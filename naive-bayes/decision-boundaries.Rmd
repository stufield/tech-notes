---
title: "Decision boundaries: Na&iuml;ve Bayes vs KNN"
author: "Stu Field"
date: "`r format(Sys.Date(), '%e %B %Y')`"
output:
  html_document:
    code_folding: show
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
 collapse = TRUE,
 comment  = "#>"
)
source("robustNaiveBayes.R")

fake_data <- function(a = 3, b = 2.14, sd = 250, pts = 200) {
  withr::local_seed(1001)
  # y.det <- a*x^b   # deterministic model
  # y <- rnorm(length(y.det), mean = y.det, sd = sd) # stochastic 'y'
  df <- data.frame(x1 = rnorm(pts, 45, 2), x2 = rnorm(pts, 75, 2))
  Response <- rep("disease", pts)
  Response[df$x1 < 44 | df$x2 <= 74] = "control"
  list(x = df, y = factor(Response))
}

fake_data2 <- function(pts = 100) {
  withr::local_seed(999)
  df1 <- data.frame(x1 = rnorm(pts, 46, 1.5), x2 = rnorm(pts, 75, 1.5)) # control
  df2 <- data.frame(x1 = rnorm(pts, 44, 1), x2 = rnorm(pts, 78, 1))     # disease
  df  <- rbind(df1, df2)
  list(x = df, y = factor(rep(c("control", "disease"), each = pts)))
}

# ----------------------------
# Calculate KNN bivariate results
# ----------------------------
predict_bivariate_knn <- function(X, newdata, y, k, ...) {
  # X: data matrix
  # newdata: new predictors to predict on
  # y: response vector
  if ( k < 2L ) {
    stop("Neighborhood (k) must be >= 1: ", k, call. = FALSE)
  }
  if ( missing(newdata) ) {
    newdata <- X
  }
  X <- data.matrix(X)
  ntr <- nrow(X)
  if ( length(y) != ntr ) {
    stop(
       sprintf("Length of class vector [y=%i] unequal to num. training samples (n=%i)",
               length(y), ntr),
       call. = FALSE)
  }
  if ( ntr < k ) {
    warning(
      sprintf("Neighborhood (k=%i) exceeds training data (n=%i) ... resetting k=%i",
              k, ntr, ntr),
      call. = FALSE)
      k <- ntr
  }
  nte <- nrow(newdata)
  idx <- seq(ntr)
  class_names <- names(table(y))
  neighbor_list <- lapply(seq(nte), function(.i) {
                          new_vals <- newdata[.i, ]
                          if ( length(new_vals) != 2L ) {
                            stop("Problem with new values ... length =",
                                 length(new_vals), call. = FALSE)
                          }
                          distances <- dist(rbind(new_vals, X), ...)[idx]
                          names(distances) <- idx
                          head(sort(distances), k)   # get the neighborhood
  })
  ret <- lapply(neighbor_list, function(.x) {
     prob <- table(y[as.numeric(names(.x))])
     prob <- unname(prob / sum(prob))[2L] # proportion disease in neighborhood
     if ( prob == 0.5 ) {
       class <- sample(class_names, 1, prob = prop.table(table(y))) # random tie-break
     } else {
       class <- ifelse(prob > 0.5, class_names[2L], class_names[1L])
     }
     data.frame(class = class, prob = prob)
  })
  do.call(rbind, ret)
}

# ------------------------
# plot a bivariate decision boundary
# ------------------------
plot_decision_boundary <- function(data, res = 100, model.type = c("knn", "bayes"),
                                   k = 15, line.col = "darkviolet", lwd = 2,
                                   lty = 2, contours = 0.5, fast = FALSE) {
  model.type <- match.arg(model.type)
  z  <- data$y
  train <- data$x
  x1 <- train[, 1L]
  x2 <- train[, 2L]
  x1grid <- seq(min(x1), max(x1), length = res)
  x2grid <- seq(min(x2), max(x2), length = res)
  grid <- data.frame(expand.grid(x1 = x1grid, x2 = x2grid))   # grid of probs

  if ( model.type == "bayes" ) {
    rm(k)
    model <- robustNaiveBayes(train, data$y)
    prob  <- predict(model, grid, type = "raw")[, "disease"]
    title <- "Naive Bayes | disease (Pr>0.5) space: "
  } else if ( model.type == "knn" ) {
    if ( fast ) {
      model <- knn(train, grid, z, k = k, prob = TRUE) # compiled code
      prob  <- attr(model, "prob")
      prob  <- ifelse(model == "disease", prob, 1 - prob)
    } else {
      model <- predict_bivariate_knn(train, grid, z, k = k, method = "mink")
      prob  <- model$prob
    }
     title <- sprintf("KNN (k=%i) | disease (Pr>0.5) space: ",k)
  } else {
    stop("Inproper [model.type=] argument passed; can be [bayes, knn]", call. = FALSE)
  }

  prob_grid <- matrix(prob, nrow = res)
  pos_space <- round(sum(prob_grid >= 0.5) / res^2, 3L)

  contour(x = x1grid, y = x2grid, z = prob_grid, levels = contours,
          lwd = lwd, lty = lty, labcex = 1, vfont = c("sans serif", "bold"),
          col = line.col, xlab = "Protein 1", ylab = "Protein 2",
          main = paste0(title, pos_space), axes = TRUE)

  points(grid, pch = ".", cex = 0.5, col = ifelse(prob >= 0.50, "red", "dodgerblue"))
  points(train, pch = 21, col = 1, bg = ifelse(z == "control", "dodgerblue", "red"))
  invisible(data)
}
```


----------


# Overview

It is sometimes nice to visualize the decision boundaries of various models.
Here we compare 2 commonly used models: na&iuml;ve Bayes and k-nearest neighbors.



## KNN vs na&iuml;ve Bayes

Below are decision boundaries for 2 simulated data sets using
K-Nearest Neighbors and na&iuml;ve Bayes models.
For the first data set (top row) the true boundary is
simulated such that disease (red) protein 1 $> 44$ and protein 2 $> 74$,
these the data are simulated with an unrealistic harsh cutoff to form
the classes (unrealistic). The lower 2 panels are more realisitic data
simulated from bivariate normal distributions and show the difference
in the boundary between the two methods.


```{r knn-vs-bayes, fig.width = 10, fig.height = 10}
par(mfrow = c(2, 2))
par(list(mgp = c(2.00, 0.75, 0.00), mar = c(3, 4, 3, 1)))
plot_decision_boundary(fake_data(), res = 175, model.type = "knn")
plot_decision_boundary(fake_data(), res = 175, model.type = "bayes")
plot_decision_boundary(fake_data2(), res = 175, model.type = "knn")
plot_decision_boundary(fake_data2(), res = 175, model.type = "bayes")
```

## Choosing *k* in KNN 

```{r knn-k, fig.width = 10, fig.height = 10}
par(list(mgp = c(2.00, 0.75, 0.00), mar = c(3, 4, 3, 1)))
par(mfrow = c(3, 3))
for ( i in 2:10 ) {
  plot_decision_boundary(fake_data(), res = 175, model.type = "knn", k = i)
}
```

------

Created by [Rmarkdown](https://github.com/rstudio/rmarkdown)
(v`r utils::packageVersion("rmarkdown")`) and `r R.version$version.string`.
